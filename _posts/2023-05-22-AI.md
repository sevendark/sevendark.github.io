---
title: "AI 笔记"
categories:
  - Tec
tags:
  - Python
  - AI
toc: true
---
记录AI相关技术学习过程，包括一些python基础知识，算法介绍

## 配置MNIST数据转化

```py
from torchvision import transforms

transformer = transforms.Compose([
    transforms.ToTensor()
])
```

通过`transforms.Composse([...])`方法可以自定义对MNIST数据的转化操作，可以添加例如转张量(tensor)，单一化（Normalization 将数据范围统一，防止数据差异过大）等操作

## 获取MNIST数据

```py
from torchvision import datasets

data = datasets.MNIST('data', 
    download=True,
    train=False,
    transform=transformer)
```

从MNIST获取数据，`'data'`是数据存储目录

## 配置数据加载方式

```py
from torch.utils.data import DataLoader

loader = DataLoader(data, batch_size=1, shuffle=True)
```

DataLoader是可迭代的内容，可使用foreach循环遍历内容，`shuffle`控制数据每次加载是否打乱顺寻，打乱顺序可避免对数据顺序的依赖

```py
import itertools
import matplotlib.pyplot as plt

for image, label in itertools.isLice(loader, 5):
    plt.axis("off")
    plt.title(label.item())
    plt.imshow(image.squeeze(), cmap="gray")
    plt.show()
```

- `axis()`方法控制是否展示图片xy标签
- `item()`方法可获取标量值
- `squeeze()`去除张量中size为1的维度
- `isLice()`方法可以将迭代器截断，此处只取用前5个值

## Python 定义模型前置知识
先放完整代码

```py
import torch.nn as nn

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = torch.relu(fc1(x))
        x = torch.relu(fc2(x))
        x = fc3(x)
        return x


```


### 定义类

```py
import torch.nn as nn

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()

    def forward():
        return 1
```
此处定义了一个最基本的模型类，`(nn.Module)`表示继承自`nn.Module`,`def __init__()` 定义了一个初始化方法，通过`super()`来调用父类方法

### Linear 线性函数

```py
import torch.nn as nn
import torch

l = nn.Linear(28 * 28, 128)
data = torch.randn((10, 28 * 28))
l(data)
```

- `Linear()`函数第一个参数为输入张量大小，第二个为输出张量大小
- `torch.randn`产生一个符合正态分布的张量，大小为(10, 28 * 28)
- `(5,)`表示一个一维五个元素的张量
- `Linear()`函数计算公式`output = input @ weight^T + bias`, `weight`(output_size, input_size)  初始为随机值，后续会根据损失函数进行调整, `bias`(output_size,) 偏置向量, `@`矩阵乘法, `^T`矩阵转置

### ReLu 函数

```py
import torch

torch.relu()
```

激活函数，提供非线性变换，公式：`ReLU(x) = max(0, x)`,取x大于0的区间


### 调整张量形状

```py
x = x.view(x.size(0), -1)
```

- `view(a, b)` 将x调整为形状为(a, b)的张量，参数`-1`表示自动计算维度大小
- `size()`获取张量的形状，参数0表示获取第一个维度的大小
